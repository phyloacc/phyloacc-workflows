#############################################################################
# Snakemake rules to classify windows in a MAF by conservation score and
# alignment depth
# Gregg Thomas, October 2023
#############################################################################

# snakemake -p -s 02_conservation_windows.smk --configfile echolocation-cfg.yaml --profile profiles/slurm_profile/ --use-conda --dryrun --rulegraph | dot -Tpng > dag.png

#############################################################################

import os
import sys

#############################################################################

PROJ_DIR = config["project_dir"];
# The root directory of the project
# All files will be saved relative to this directory

PREFIX = config["prefix"];
# The prefix for all output files

CHROMES = config["chromes"];
# The list of chromosomes to process

ALPHA = str(config["alpha"]);
# The alpha level to consider a site to be conserved

ALN_DEPTH_THRESHOLD = [ str(threshold) for threshold in config["aln_depth_threshold"] ];
# The number of taxa that must be present at any site in the alignment to consider it high depth

CONSERVED_THRESHOLD = [ str(threshold) for threshold in config["conserved_threshold"] ];
# The number of high depth, conserved sites in a window to consider it a conserved element

MAF_OUTDIR = config["mafoutdir"];
# The output directory for all MAF-related files

TMPDIR = config["tmp_dir"];
# A temporary directory for intermediate files

## Project and run information
#####

MAF_DIR = config["mafdir"];
MAF_FILE = config["maf"];
MAF_PATH = os.path.join(MAF_DIR, MAF_FILE);
# The MAF file to process

MAF_REF_ID = config["maf_ref_id"];
MAF_CHR_PREFIX = config["maf_chr_prefix"];
MAF_REF_CHR_JOINER = config["maf_ref_chr_joiner"];
MAF_REF_PREFIX = MAF_REF_ID + MAF_REF_CHR_JOINER + MAF_CHR_PREFIX;
# The prefix for the reference chromosome in the MAF file

MAF_SPLIT_MB = str(config["maf_split_size_mb"]);
MAF_SPLIT_CHR_DIR = os.path.join(MAF_DIR, PREFIX + "-mafSplit");
MAF_SPLIT_MB_DIR = os.path.join(MAF_DIR, PREFIX + "-mafSplit-" + MAF_SPLIT_MB + "Mb");
# Info for splitting the MAF file into smaller chunks

## MAF 
#####

PHYLOP_BIGWIG = config["phylop_bigwig"];
# The bigwig file with phylop scores
# Eventually, this will be generated by the pipeline

## Phylop
#####

REF_DIR = config["ref_dir"];
# The directory with reference files

REF_CHR_BED = config["chr_bed"];
REF_CHR_BED = os.path.join(REF_DIR, REF_CHR_BED);

REF_SPLIT_BED = config["ref_split_bed"];
REF_SPLIT_BED = os.path.join(REF_DIR, REF_SPLIT_BED);
# The bed file with the windows to split the MAF file into

REF_ELEMENT_BED = config["element_size_bed"];
REF_ELEMENT_BED = os.path.join(REF_DIR, REF_ELEMENT_BED);
# The bed file with the windows to predict conserved elements

## Reference files
#####

chr_counts = {};
chr_list, win_list = [], [];

for line in open(REF_SPLIT_BED):
    cur_chr = line.strip().split("\t")[0];

    if cur_chr not in chr_counts:
        chr_counts[cur_chr] = 0;

    chr_list.append(cur_chr);

    if chr_counts[cur_chr] == 0:
        chr_counts[cur_chr] += 1;
        continue;
    # Not sure why mafSplit starts at 1, but it does

    cur_win = str(chr_counts[cur_chr]);
    while len(cur_win) < 2:
        cur_win = "0" + cur_win;
    win_list.append(cur_win);

    chr_counts[cur_chr] += 1;
# Get the list of chromosomes and windows to process

#############################################################################

rule all:
    input:
        expand(os.path.join(PROJ_DIR, "summary-data", "site-counts", "depth", PREFIX + ".{chrome}.maf-depth-site-counts.tsv"), chrome=chr_list),
        # depth_site_counts

        os.path.join(PROJ_DIR, "summary-data", "site-counts", "conserved", PREFIX + ".conserved-site-counts." + ALPHA + ".tsv"),
        # conserved_site_counts

        expand(os.path.join(PROJ_DIR, "summary-data", "site-counts", "conserved-high-depth", "{aln_depth_threshold}", PREFIX + ".{chrome}.conserved-high-depth-site-counts." + ALPHA + ".{aln_depth_threshold}.tsv"), chrome=chr_list, aln_depth_threshold=ALN_DEPTH_THRESHOLD),
        # conserved_high_depth_site_counts

        expand(os.path.join(PROJ_DIR, "summary-data", "site-counts", "conserved-elements", "{aln_depth_threshold}",  PREFIX + ".conserved-element-counts." + ALPHA + ".{aln_depth_threshold}.{conserved_threshold}.tsv"), aln_depth_threshold=ALN_DEPTH_THRESHOLD, conserved_threshold=CONSERVED_THRESHOLD),
        # conserved_element_counts

        expand(os.path.join(MAF_OUTDIR, "07-conserved-elements-chr", "{chrome}", "{aln_depth_threshold}", PREFIX + ".phylop-conserved-windows.{chrome}." + ALPHA  + ".{aln_depth_threshold}.{conserved_threshold}.bed"), chrome=chr_list, aln_depth_threshold=ALN_DEPTH_THRESHOLD, conserved_threshold=CONSERVED_THRESHOLD),
        # get_conserved_elements_chr

        expand(os.path.join(MAF_SPLIT_CHR_DIR, "{chrome}.00.mdx"), chrome=chr_list),
        # split_maf_index

        expand(os.path.join(MAF_OUTDIR, "08-conserved-elements-chr-fasta", "{chrome}", "{aln_depth_threshold}-{conserved_threshold}"), chrome=chr_list, aln_depth_threshold=ALN_DEPTH_THRESHOLD, conserved_threshold=CONSERVED_THRESHOLD),
        # get_sequences_chr

#############################################################################

# rule run_phylop
## TODO

####################

rule convert_phylop_bigwig:
    input:
        phylop_bigwig = PHYLOP_BIGWIG
    output:
        phylop_scores = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.tsv")
    log:
        os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", "logs", PREFIX + ".phylop-scores.log")
    resources:
        time = "6:00:00",
        mem = "24g"
    conda:
        "envs/ucsc-bigwigtowig.yml"
        # UCSC tools need their own environment right now because some of them require an outdated
        # openssl library (1.0.0) that doesn't play nice with other tools
    shell:
        """
        bigWigToWig {input.phylop_bigwig} /dev/stdout | \
        grep -v "^#" | \
        awk -v OFS="\\t" '{{ if ($4 > 0) print $0, "0", 10^-$4; else if ($4 < 0) print $0, "2", 10^$4; else print $0, "1", 10^$4 }}' 2> {log} > {output.phylop_scores}
        """
# Convert bigwig to wig and add new columns with the conservation status, raw p-value
# HEADERS:
# 1. chromosome
# 2. start position
# 3. end position
# 4. raw score/log(raw p-value)
# 5. conservation status (0 = conserved, 1 = neutral, 2 = accelerated)
# 6. raw p-value
# 945.29user 22.20system 45:11.77elapsed 35%CPU (0avgtext+0avgdata 1238900maxresident)k
# 19289288inputs+0outputs (0major+29267minor)pagefaults 0swaps

####################

rule adjust_pvals:
    input:
        phylop_scores = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.tsv")
    output:
        fdr_adj_scores = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".tsv")
    params:
        alpha = ALPHA,
        tmp_dir = TMPDIR
    log:
        os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", "logs", PREFIX + ".phylop-scores.fdr-" + ALPHA + ".log")
    resources:
        cpus = 32,
        time = "72:00:00",
        mem = "64g"
    shell:
        """
        total=$(wc -l {input.phylop_scores} | cut -d ' ' -f1)

        sort -k6,6g --parallel={resources.cpus} -T {params.tmp_dir} {input.phylop_scores} | \
        awk -v OFS="\\t" '{{ print $0, NR }}' | \
        sort -rn -k7 --parallel={resources.cpus} -T {params.tmp_dir} | \
        awk -v OFS="\\t" -v total=${{total}} 'BEGIN{{prev_pn=999}} {{p_adj=(total/$7)*$6; if(p_adj>prev_pn){{p_adj=prev_pn}}; prev_pn=p_adj; if(p_adj>1){{p_adj=1}}; sig=0; if(p_adj<0.05){{sig=1}}; print $0, p_adj, sig}}' | \
        sort -k 1,1 -k2,2n --parallel={resources.cpus} -T {params.tmp_dir} |\
        cut -f 1,2,3,5,8,9 2> {log} > {output.fdr_adj_scores}
        """
# Adjust the raw phylop p-values for multiple testing using the Benjamini-Hochberg method
# STEPS:
# 1. Sort by p-value in ascending order
# 2. Add a column with the row number as the rank of that p-value
# 3. Sort by p-value in descending order so it is easy to check the adjusted p-value of the next highest raw p-value as per the BH method
# 4. Calculate the adjusted p-value using the formula: p_adj = (total number of tests / rank of p-value) * raw p-value
#       If the adjusted p-value is greater than the previous adjusted p-value, set the adjusted p-value to the previous adjusted p-value
#       If the adjusted p-value is greater than 1, set the adjusted p-value to 1
#       Add a column with the adjusted p-value
#       Add a column with the significance status (0 = not significant, 1 = significant)
# 9. Sort by chromosome and then by position numerically
# 10. Remove the row number and raw p-value columns
# 11. Write the output to a new file
# HEADERS:
# 1. chromosome
# 2. start position
# 3. end position
# 4. conservation status (0 = conserved, 1 = neutral, 2 = accelerated)
# 5. adjusted p-value
# 6. significant (0 = not significant, 1 = significant)
## Took a couple of days because I forgot the parallel option on the last sort

####################

rule get_conserved_sites:
    input:
        fdr_adj_scores = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".tsv")
    output:
        conserved_sites = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.tsv")
    log:
        os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", "logs", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.log")
    shell:
        """
        awk -v OFS='\\t' '$4=="0" && $6=="1"{{print $1, $2, $3, $4$6}}' {input.fdr_adj_scores} 2> {log} > {output.conserved_sites}
        """

####################

rule conserved_site_counts:
    input:
        conserved_sites = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.tsv")
    output:
        conserved_site_counts = os.path.join(PROJ_DIR, "summary-data", "site-counts", "conserved", PREFIX + ".conserved-site-counts." + ALPHA + ".tsv")
    shell:
        """
        awk '{{ count[$1]++ }} END {{ for (num in count) print num, count[num] }}' {input.conserved_sites} > {output.conserved_site_counts}
        """

####################

# rule get_conserved_bed:
#     input:
#         conserved_sites = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.tsv")
#     output:
#         conserved_bed = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.bed")
#     log:
#         os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", "logs", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.bed.log")
#     conda:
#         "envs/ucsc-bedgraphpack.yml"
#         # bedGraphPack needs its own environment right now because the current version (377) requires an outdated
#         # openssl library (1.0.0) that doesn't play nice with other tools        
#     shell:
#         """
#         bedGraphPack {input.conserved_sites} {output.conserved_bed} 2> {log}
#         """

## Count conserved sites in each window:
## WD: MAF_OUTDIR/04-phylop-bedgraph
## bedtools intersect -a ../../00-human-ref-ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.200bp-windows.bed -b 241-mammalian-2020v2b.phylop-scores.fdr-adj-0.05.conserved.bed -c | awk '{ count[$4]++ } END { for (num in count) print num, count[num] }' &> ../../../summary-data/241-mammalian-conserved-sites-per-window-200bp.txt        

####################

rule split_maf:
    input:
        maf = MAF_PATH,
        split_bed = REF_SPLIT_BED
    output:
        outdir = directory(MAF_SPLIT_MB_DIR),
        split_maf = expand(os.path.join(MAF_SPLIT_MB_DIR, "{chrome}.{win}.maf"), zip, chrome=chr_list, win=win_list)
    params:
        prefix = MAF_SPLIT_MB_DIR
    conda:
        "envs/ucsc-mafsplit.yml"
        # mafSplit needs its own environment right now because the current version (377) requires an outdated
        # openssl library (1.0.0) that doesn't play nice with other tools
    resources:
        partition="intermediate",
        mem="48g",
        time="120:00:00"
    shell:
        """
        mkdir -p {output.outdir}
        mafSplit {input.split_bed} {params.prefix} {input.maf}
        """
# On holybioinf:
# Splitting 1 files from /n/holylfs05/LABS/informatics/Users/gthomas/phyloacc-sicb/data/00-human-ref-ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.chr.1Mb.bed to /n/holyscratch01/informatics/gwct/241-mammalian-2020v2b-mafSplit-1Mb/
# splitting /n/holyscratch01/informatics/gwct/241-mammalian-2020v2b.maf
# 79436.85user 11923.47system 25:28:11elapsed 99%CPU (0avgtext+0avgdata 7304maxresident)k
# 17477696inputs+20200869936outputs (0major+9728minor)pagefaults 0swaps
#
# maybe just use msa_split so we don't have to have another dependency?
# though i think mafSplit is more versatile...

####################

rule get_maf_depth:
    input:
        split_maf = os.path.join(MAF_SPLIT_MB_DIR, "{chrome}.{win}.maf")
    output:
        split_wig = os.path.join(MAF_OUTDIR, "03-aln-depth", "{chrome}.{win}.maf-depth.wig")
    params:
        chrome = "{chrome}"
    log:
        os.path.join(MAF_OUTDIR, "03-aln-depth", "logs", "{chrome}.{win}.maf-depth.log")
    shell:
        """
        python maf_depth.py {input.split_maf} {params.chrome} {output.split_wig} > {log}
        """

####################

rule depth_site_counts:
    input:
        split_wig = expand(os.path.join(MAF_OUTDIR, "03-aln-depth", "{chrome}.{win}.maf-depth.wig"), zip, chrome=chr_list, win=win_list)
    output:
        depth_site_counts_chr = os.path.join(PROJ_DIR, "summary-data", "site-counts", "depth", PREFIX + ".{chrome}.maf-depth-site-counts.tsv")
    params:
        depth_dir = os.path.join(MAF_OUTDIR, "03-aln-depth"),
        chrome = "{chrome}"
    shell:
        """
        awk '{{ count[$4]++ }} END {{ for (num in count) print num, count[num] }}' {params.depth_dir}/{params.chrome}.*.maf-depth.wig > {output.depth_site_counts_chr}
        """
        
####################

rule combine_high_depth_by_chr:
    input:
        split_wig = expand(os.path.join(MAF_OUTDIR, "03-aln-depth", "{chrome}.{win}.maf-depth.wig"), zip, chrome=chr_list, win=win_list)
    output:
        chr_wig = os.path.join(MAF_OUTDIR, "04-aln-depth-chr", "{aln_depth_threshold}", PREFIX + ".{chrome}.maf-depth.{aln_depth_threshold}.wig")
    params:
        aln_depth_threshold = "{aln_depth_threshold}",
        depth_dir = os.path.join(MAF_OUTDIR, "03-aln-depth"),
        chrome = "{chrome}",
        tmp_dir = TMPDIR
    resources:
        cpus = 4
    shell:
        """
        cat {params.depth_dir}/{params.chrome}.*.maf-depth.wig | \
        awk -v OFS='\\t' '$4>{params.aln_depth_threshold}{{print}}' | \
        sort -k 1,1 -k2,2n --parallel={resources.cpus} -T {params.tmp_dir} > {output.chr_wig}
        """

####################

rule get_high_depth_conserved_sites_by_chr:
    input:
        conserved_sites = os.path.join(MAF_OUTDIR, "04-phylop-bedgraph", PREFIX + ".phylop-scores.fdr-adj-" + ALPHA + ".conserved.tsv"),
        high_depth_sites_chr = os.path.join(MAF_OUTDIR, "04-aln-depth-chr", "{aln_depth_threshold}", PREFIX + ".{chrome}.maf-depth.{aln_depth_threshold}.wig")
    output:
        conserved_high_depth_sites_chr = os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "{aln_depth_threshold}", PREFIX + ".conserved.sites.{chrome}." + ALPHA + ".{aln_depth_threshold}.wig")
    log:
        os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "logs", PREFIX + ".conserved.sites.{chrome}" + ALPHA + ".{aln_depth_threshold}.bed.log")
    resources:
        mem = "128g"
    shell:
        """
        bedtools intersect -a {input.conserved_sites} -b {input.high_depth_sites_chr} -wo 2> {log} > {output.conserved_high_depth_sites_chr}
        """

####################

rule conserved_high_depth_site_counts:
    input:
        conserved_high_depth_sites_chr = os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "{aln_depth_threshold}", PREFIX + ".conserved.sites.{chrome}." + ALPHA + ".{aln_depth_threshold}.wig")
    output:
        conserved_high_depth_site_counts_chr = os.path.join(PROJ_DIR, "summary-data", "site-counts", "conserved-high-depth", "{aln_depth_threshold}", PREFIX + ".{chrome}.conserved-high-depth-site-counts." + ALPHA + ".{aln_depth_threshold}.tsv")
    params:
        conserved_high_depth_dir = os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "{aln_depth_threshold}"),
        prefix = PREFIX,
        chrome = "{chrome}",
        alpha = ALPHA,
        aln_depth_threshold = "{aln_depth_threshold}"
    shell:
        """
        awk '{{ count[$4]++ }} END {{ for (num in count) print num, count[num] }}' {params.conserved_high_depth_dir}/{params.prefix}.conserved.sites.{params.chrome}.{params.alpha}.{params.aln_depth_threshold}.wig > {output.conserved_high_depth_site_counts_chr}
        """

####################

rule combine_high_depth_conserved_sites:
    input:
        conserved_high_depth_sites_chr = expand(os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "{{aln_depth_threshold}}", PREFIX + ".conserved.sites.{chrome}." + ALPHA + ".{{aln_depth_threshold}}.wig"), chrome=chr_list)
    output:
        conserved_high_depth_sites = os.path.join(MAF_OUTDIR, "06-conserved-sites", "{aln_depth_threshold}", PREFIX + ".conserved.sites." + ALPHA + ".{aln_depth_threshold}.wig")
    params:
        conserved_high_depth_dir = os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "{aln_depth_threshold}"),
        prefix = PREFIX,
        alpha = ALPHA,
        aln_depth_threshold = "{aln_depth_threshold}"        
    shell:
        """
        cat {params.conserved_high_depth_dir}/{params.prefix}.conserved.sites.*.{params.alpha}.{params.aln_depth_threshold}.wig > {output.conserved_high_depth_sites}
        """

####################

# rule merge_conserved_sites:
#     input:
#         conserved_high_depth_sites = os.path.join(MAF_OUTDIR, "06-conserved-sites", "{aln_depth_threshold}", PREFIX + ".conserved.sites." + ALPHA + ".{aln_depth_threshold}.wig")
#     output:
#         conserved_high_depth_sites_bed = os.path.join(MAF_OUTDIR, "06-conserved-sites", "{aln_depth_threshold}", PREFIX + ".conserved.sites." + ALPHA + ".{aln_depth_threshold}.bed")
#     log:
#         os.path.join(MAF_OUTDIR, "06-conserved-sites", "logs", PREFIX + ".conserved.sites." + ALPHA + ".{aln_depth_threshold}.bed.log")     
#     shell:
#         """
#         bedtools merge -i {input.conserved_high_depth_sites} 2> {log} > {output.conserved_high_depth_sites_bed}
#         """    

####################

rule get_conserved_elements:
    input:
        conserved_high_depth_sites_bed = expand(os.path.join(MAF_OUTDIR, "06-conserved-sites", "{{aln_depth_threshold}}", PREFIX + ".conserved.sites." + ALPHA + ".{{aln_depth_threshold}}.wig"), aln_depth_threshold=ALN_DEPTH_THRESHOLD),
        windows_bed = REF_ELEMENT_BED
    output:
        conserved_windows = os.path.join(MAF_OUTDIR, "07-conserved-elements", "{aln_depth_threshold}", PREFIX + ".phylop-conserved-windows." + ALPHA  + ".{aln_depth_threshold}.{conserved_threshold}.bed")
    params:
        conserved_threshold = "{conserved_threshold}"
    log:
        os.path.join(MAF_OUTDIR, "07-conserved-elements", "logs", PREFIX + ".phylop-conserved-windows." + ALPHA + ".{aln_depth_threshold}.{conserved_threshold}.bed.log")
    resources:
        mem = "128g"
    shell:
        """
        bedtools intersect -a {input.windows_bed} -b {input.conserved_high_depth_sites_bed} -c | \
        awk '$4 >= {params.conserved_threshold} {{print}}' | \
        bedtools merge -d 5 -i - 2> {log} > {output.conserved_windows}
        """

####################

rule get_conserved_elements_chr:
    input:
        conserved_high_depth_sites_chr_bed = os.path.join(MAF_OUTDIR, "05-conserved-sites-chr", "{aln_depth_threshold}", PREFIX + ".conserved.sites.{chrome}." + ALPHA + ".{aln_depth_threshold}.wig"),
        windows_bed = REF_ELEMENT_BED
    output:
        conserved_windows = os.path.join(MAF_OUTDIR, "07-conserved-elements-chr", "{chrome}", "{aln_depth_threshold}", PREFIX + ".phylop-conserved-windows.{chrome}." + ALPHA  + ".{aln_depth_threshold}.{conserved_threshold}.bed")
    params:
        conserved_threshold = "{conserved_threshold}"
    log:
        os.path.join(MAF_OUTDIR, "07-conserved-elements-chr", "logs", PREFIX + ".phylop-conserved-windows.{chrome}." + ALPHA + ".{aln_depth_threshold}.{conserved_threshold}.bed.log")
    resources:
        mem = "24g"
    shell:
        """
        bedtools intersect -a {input.windows_bed} -b {input.conserved_high_depth_sites_chr_bed} -c | \
        awk '$4 >= {params.conserved_threshold} {{print}}' | \
        bedtools merge -d 5 -i - 2> {log} > {output.conserved_windows}
        """

####################

rule conserved_element_counts:
    input:
        conserved_windows = os.path.join(MAF_OUTDIR, "07-conserved-elements", "{aln_depth_threshold}", PREFIX + ".phylop-conserved-windows." + ALPHA  + ".{aln_depth_threshold}.{conserved_threshold}.bed")
    output:
        conserved_element_counts = os.path.join(PROJ_DIR, "summary-data", "site-counts", "conserved-elements", "{aln_depth_threshold}", PREFIX + ".conserved-element-counts." + ALPHA + ".{aln_depth_threshold}.{conserved_threshold}.tsv")
    shell:
        """
        awk '{{ count[$1]++ }} END {{ for (num in count) print num, count[num] }}' {input.conserved_windows} > {output.conserved_element_counts}
        """

####################

rule split_maf_chr:
    input:
        maf = MAF_PATH,
        split_bed = REF_CHR_BED
    output:
        outdir = directory(MAF_SPLIT_CHR_DIR),
        split_maf = expand(os.path.join(MAF_SPLIT_CHR_DIR, "{chrome}.00.maf"), chrome=chr_list)
    params:
        prefix = MAF_SPLIT_CHR_DIR
    conda:
        "envs/ucsc-mafsplit.yml"
        # mafSplit needs its own environment right now because the current version (377) requires an outdated
        # openssl library (1.0.0) that doesn't play nice with other tools
    resources:
        partition="intermediate",
        mem="48g",
        time="120:00:00"
    shell:
        """
        mkdir -p {output.outdir}
        mafSplit {input.split_bed} {params.prefix} {input.maf}
        """
        
####################

rule index_maf_chr:
    input:
        split_maf = os.path.join(MAF_SPLIT_CHR_DIR, "{chrome}.00.maf")
    output:
        split_maf_index = os.path.join(MAF_SPLIT_CHR_DIR, "{chrome}.00.mdx")
    resources:
        partition="intermediate",
        mem="48g",
        time="120:00:00"
    shell:
        """
        python maf-scripts/maf_index.py {input.split_maf} {output.split_maf_index}
        """

####################

rule get_sequences_chr:
    input:
        split_maf = os.path.join(MAF_SPLIT_CHR_DIR, "{chrome}.00.maf"),
        split_maf_index = os.path.join(MAF_SPLIT_CHR_DIR, "{chrome}.00.mdx"),
        conserved_windows = os.path.join(MAF_OUTDIR, "07-conserved-elements-chr", "{chrome}", "{aln_depth_threshold}", PREFIX + ".phylop-conserved-windows.{chrome}." + ALPHA  + ".{aln_depth_threshold}.{conserved_threshold}.bed")
    output:
        seq_dir = directory(os.path.join(MAF_OUTDIR, "08-conserved-elements-chr-fasta", "{chrome}", "{aln_depth_threshold}-{conserved_threshold}"))
    params:
        ref_id = MAF_REF_ID
    shell:
        """
        python maf-scripts/maf_fetch.py {input.split_maf} {input.split_maf_index} {params.ref_id} {input.conserved_windows} {output.seq_dir} 
        """


#############################################################################
